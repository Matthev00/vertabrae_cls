{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Literal, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def conv3x3x3(in_planes: int, out_planes: int, stride: int = 1, dilation: int = 1) -> nn.Conv3d:\n",
    "    \"\"\"3x3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        dilation=dilation,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def downsample_basic_block(\n",
    "    x: torch.Tensor, planes: int, stride: int, no_cuda: bool = False\n",
    ") -> torch.Tensor:\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(\n",
    "        out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4)\n",
    "    ).zero_()\n",
    "    if not no_cuda:\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        downsample: bool = None,\n",
    "    ):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        downsample: bool = None,\n",
    "    ):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "            padding=dilation,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Union[Bottleneck, BasicBlock],\n",
    "        layers: list[int],\n",
    "        num_classes: int = 10,\n",
    "        shortcut_type: Literal[\"A\", \"B\"] = \"B\",\n",
    "        no_cuda: bool = False,\n",
    "    ):\n",
    "        self.inplanes = 64\n",
    "        self.no_cuda = no_cuda\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            1, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], shortcut_type, stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], shortcut_type, stride=1, dilation=4)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode=\"fan_out\")\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Union[Bottleneck, BasicBlock],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        shortcut_type: Literal[\"A\", \"B\"],\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "    ):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == \"A\":\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride,\n",
    "                    no_cuda=self.no_cuda,\n",
    "                )\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    nn.BatchNorm3d(planes * block.expansion),\n",
    "                )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample)\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_resnet(model_depth: int = 18, **kwargs):\n",
    "    \"\"\"\n",
    "    Get a ResNet model based on the specified depth.\n",
    "\n",
    "    Args:\n",
    "        model_depth (int): Depth of the ResNet model (e.g., 10, 18, 34, 50, 101, 152, 200).\n",
    "        **kwargs: Additional arguments for the ResNet constructor.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The ResNet model.\n",
    "    \"\"\"\n",
    "    if model_depth == 10:\n",
    "        return resnet10(**kwargs)\n",
    "    elif model_depth == 18:\n",
    "        return resnet18(**kwargs)\n",
    "    elif model_depth == 34:\n",
    "        return resnet34(**kwargs)\n",
    "    elif model_depth == 50:\n",
    "        return resnet50(**kwargs)\n",
    "    elif model_depth == 101:\n",
    "        return resnet101(**kwargs)\n",
    "    elif model_depth == 152:\n",
    "        return resnet152(**kwargs)\n",
    "    elif model_depth == 200:\n",
    "        return resnet200(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ResNet depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mateusz/DATA/tmp/ipykernel_236312/1585434404.py:161: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode=\"fan_out\")\n"
     ]
    }
   ],
   "source": [
    "model = get_resnet(model_depth=18, num_classes=10, no_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from src.modeling.base_model import VertebraeClassifier\n",
    "from src.modeling.resnet3d import get_resnet\n",
    "\n",
    "\n",
    "class Med3DClassifier(VertebraeClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        model_depth: int = 18,\n",
    "        shortcut_type: Literal[\"A\", \"B\"] = \"B\",\n",
    "        load_pretrained: bool = True,\n",
    "        freeze_backbone: bool = True,\n",
    "        device: torch.device = torch.device(\"cuda\"),\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Classifier using Med3D ResNet backbone with optional pretrained weights.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            model_depth (int): Depth of ResNet (e.g., 10, 18, 34...).\n",
    "            shortcut_type (Literal['A', 'B']): Type of shortcut connection.\n",
    "            load_pretrained (bool): Whether to load pretrained weights from Med3D.\n",
    "            freeze_backbone (bool): Whether to freeze the backbone weights.\n",
    "        \"\"\"\n",
    "        super().__init__(num_classes)\n",
    "        self.device = device\n",
    "\n",
    "        self.model = get_resnet(\n",
    "            model_depth=model_depth,\n",
    "            num_classes=num_classes,\n",
    "            shortcut_type=shortcut_type,\n",
    "        )\n",
    "\n",
    "        if load_pretrained is not None:\n",
    "            self._load_med3d_weights(model_depth)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def _load_med3d_weights(self, model_depth: int) -> None:\n",
    "        \"\"\"\n",
    "        Load pretrained Med3D weights from HuggingFace, skipping the classification layer.\n",
    "        \"\"\"\n",
    "        hf_mapping = {\n",
    "            10: (\"TencentMedicalNet/MedicalNet-ResNet10\", \"resnet_10.pth\"),\n",
    "            18: (\"TencentMedicalNet/MedicalNet-ResNet18\", \"resnet_18.pth\"),\n",
    "            34: (\"TencentMedicalNet/MedicalNet-ResNet34\", \"resnet_34.pth\"),\n",
    "            50: (\"TencentMedicalNet/MedicalNet-ResNet50\", \"resnet_50.pth\"),\n",
    "            101: (\"TencentMedicalNet/MedicalNet-ResNet101\", \"resnet_101.pth\"),\n",
    "            152: (\"TencentMedicalNet/MedicalNet-ResNet152\", \"resnet_152.pth\"),\n",
    "            200: (\"TencentMedicalNet/MedicalNet-ResNet200\", \"resnet_200.pth\"),\n",
    "        }\n",
    "\n",
    "        if model_depth not in hf_mapping:\n",
    "            raise ValueError(f\"No pretrained weights available for model depth {model_depth}\")\n",
    "\n",
    "        repo_id, filename = hf_mapping[model_depth]\n",
    "        weight_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "\n",
    "        state_dict = torch.load(weight_path, map_location=self.device)[\"state_dict\"]\n",
    "        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items() if not k.startswith(\"conv-seg\")}            \n",
    "\n",
    "        missing, unexpected = self.model.load_state_dict(state_dict, strict=False)\n",
    "        print(\n",
    "            f\"[Med3D] Loaded weights with {len(missing)} missing and {len(unexpected)} unexpected keys. {len(state_dict)} total keys loaded.\" \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: torch.Size([64, 1, 7, 7, 7])\n",
      "bn1.weight: torch.Size([64])\n",
      "bn1.bias: torch.Size([64])\n",
      "bn1.running_mean: torch.Size([64])\n",
      "bn1.running_var: torch.Size([64])\n",
      "bn1.num_batches_tracked: torch.Size([])\n",
      "layer1.0.conv1.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "layer1.0.bn1.weight: torch.Size([64])\n",
      "layer1.0.bn1.bias: torch.Size([64])\n",
      "layer1.0.bn1.running_mean: torch.Size([64])\n",
      "layer1.0.bn1.running_var: torch.Size([64])\n",
      "layer1.0.bn1.num_batches_tracked: torch.Size([])\n",
      "layer1.0.conv2.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "layer1.0.bn2.weight: torch.Size([64])\n",
      "layer1.0.bn2.bias: torch.Size([64])\n",
      "layer1.0.bn2.running_mean: torch.Size([64])\n",
      "layer1.0.bn2.running_var: torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked: torch.Size([])\n",
      "layer2.0.conv1.weight: torch.Size([128, 64, 3, 3, 3])\n",
      "layer2.0.bn1.weight: torch.Size([128])\n",
      "layer2.0.bn1.bias: torch.Size([128])\n",
      "layer2.0.bn1.running_mean: torch.Size([128])\n",
      "layer2.0.bn1.running_var: torch.Size([128])\n",
      "layer2.0.bn1.num_batches_tracked: torch.Size([])\n",
      "layer2.0.conv2.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "layer2.0.bn2.weight: torch.Size([128])\n",
      "layer2.0.bn2.bias: torch.Size([128])\n",
      "layer2.0.bn2.running_mean: torch.Size([128])\n",
      "layer2.0.bn2.running_var: torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked: torch.Size([])\n",
      "layer2.0.downsample.0.weight: torch.Size([128, 64, 1, 1, 1])\n",
      "layer2.0.downsample.1.weight: torch.Size([128])\n",
      "layer2.0.downsample.1.bias: torch.Size([128])\n",
      "layer2.0.downsample.1.running_mean: torch.Size([128])\n",
      "layer2.0.downsample.1.running_var: torch.Size([128])\n",
      "layer2.0.downsample.1.num_batches_tracked: torch.Size([])\n",
      "layer3.0.conv1.weight: torch.Size([256, 128, 3, 3, 3])\n",
      "layer3.0.bn1.weight: torch.Size([256])\n",
      "layer3.0.bn1.bias: torch.Size([256])\n",
      "layer3.0.bn1.running_mean: torch.Size([256])\n",
      "layer3.0.bn1.running_var: torch.Size([256])\n",
      "layer3.0.bn1.num_batches_tracked: torch.Size([])\n",
      "layer3.0.conv2.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "layer3.0.bn2.weight: torch.Size([256])\n",
      "layer3.0.bn2.bias: torch.Size([256])\n",
      "layer3.0.bn2.running_mean: torch.Size([256])\n",
      "layer3.0.bn2.running_var: torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked: torch.Size([])\n",
      "layer3.0.downsample.0.weight: torch.Size([256, 128, 1, 1, 1])\n",
      "layer3.0.downsample.1.weight: torch.Size([256])\n",
      "layer3.0.downsample.1.bias: torch.Size([256])\n",
      "layer3.0.downsample.1.running_mean: torch.Size([256])\n",
      "layer3.0.downsample.1.running_var: torch.Size([256])\n",
      "layer3.0.downsample.1.num_batches_tracked: torch.Size([])\n",
      "layer4.0.conv1.weight: torch.Size([512, 256, 3, 3, 3])\n",
      "layer4.0.bn1.weight: torch.Size([512])\n",
      "layer4.0.bn1.bias: torch.Size([512])\n",
      "layer4.0.bn1.running_mean: torch.Size([512])\n",
      "layer4.0.bn1.running_var: torch.Size([512])\n",
      "layer4.0.bn1.num_batches_tracked: torch.Size([])\n",
      "layer4.0.conv2.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "layer4.0.bn2.weight: torch.Size([512])\n",
      "layer4.0.bn2.bias: torch.Size([512])\n",
      "layer4.0.bn2.running_mean: torch.Size([512])\n",
      "layer4.0.bn2.running_var: torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked: torch.Size([])\n",
      "layer4.0.downsample.0.weight: torch.Size([512, 256, 1, 1, 1])\n",
      "layer4.0.downsample.1.weight: torch.Size([512])\n",
      "layer4.0.downsample.1.bias: torch.Size([512])\n",
      "layer4.0.downsample.1.running_mean: torch.Size([512])\n",
      "layer4.0.downsample.1.running_var: torch.Size([512])\n",
      "layer4.0.downsample.1.num_batches_tracked: torch.Size([])\n",
      "[Med3D] Loaded weights with 2 missing and 0 unexpected keys. 72 total keys loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Med3DClassifier(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model \n",
    "model_path = \"med3d_resnet10.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_2 = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight: torch.Size([64, 1, 7, 7, 7])\n",
      "model.bn1.weight: torch.Size([64])\n",
      "model.bn1.bias: torch.Size([64])\n",
      "model.bn1.running_mean: torch.Size([64])\n",
      "model.bn1.running_var: torch.Size([64])\n",
      "model.bn1.num_batches_tracked: torch.Size([])\n",
      "model.layer1.0.conv1.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "model.layer1.0.bn1.weight: torch.Size([64])\n",
      "model.layer1.0.bn1.bias: torch.Size([64])\n",
      "model.layer1.0.bn1.running_mean: torch.Size([64])\n",
      "model.layer1.0.bn1.running_var: torch.Size([64])\n",
      "model.layer1.0.bn1.num_batches_tracked: torch.Size([])\n",
      "model.layer1.0.conv2.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "model.layer1.0.bn2.weight: torch.Size([64])\n",
      "model.layer1.0.bn2.bias: torch.Size([64])\n",
      "model.layer1.0.bn2.running_mean: torch.Size([64])\n",
      "model.layer1.0.bn2.running_var: torch.Size([64])\n",
      "model.layer1.0.bn2.num_batches_tracked: torch.Size([])\n",
      "model.layer2.0.conv1.weight: torch.Size([128, 64, 3, 3, 3])\n",
      "model.layer2.0.bn1.weight: torch.Size([128])\n",
      "model.layer2.0.bn1.bias: torch.Size([128])\n",
      "model.layer2.0.bn1.running_mean: torch.Size([128])\n",
      "model.layer2.0.bn1.running_var: torch.Size([128])\n",
      "model.layer2.0.bn1.num_batches_tracked: torch.Size([])\n",
      "model.layer2.0.conv2.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "model.layer2.0.bn2.weight: torch.Size([128])\n",
      "model.layer2.0.bn2.bias: torch.Size([128])\n",
      "model.layer2.0.bn2.running_mean: torch.Size([128])\n",
      "model.layer2.0.bn2.running_var: torch.Size([128])\n",
      "model.layer2.0.bn2.num_batches_tracked: torch.Size([])\n",
      "model.layer2.0.downsample.0.weight: torch.Size([128, 64, 1, 1, 1])\n",
      "model.layer2.0.downsample.1.weight: torch.Size([128])\n",
      "model.layer2.0.downsample.1.bias: torch.Size([128])\n",
      "model.layer2.0.downsample.1.running_mean: torch.Size([128])\n",
      "model.layer2.0.downsample.1.running_var: torch.Size([128])\n",
      "model.layer2.0.downsample.1.num_batches_tracked: torch.Size([])\n",
      "model.layer3.0.conv1.weight: torch.Size([256, 128, 3, 3, 3])\n",
      "model.layer3.0.bn1.weight: torch.Size([256])\n",
      "model.layer3.0.bn1.bias: torch.Size([256])\n",
      "model.layer3.0.bn1.running_mean: torch.Size([256])\n",
      "model.layer3.0.bn1.running_var: torch.Size([256])\n",
      "model.layer3.0.bn1.num_batches_tracked: torch.Size([])\n",
      "model.layer3.0.conv2.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "model.layer3.0.bn2.weight: torch.Size([256])\n",
      "model.layer3.0.bn2.bias: torch.Size([256])\n",
      "model.layer3.0.bn2.running_mean: torch.Size([256])\n",
      "model.layer3.0.bn2.running_var: torch.Size([256])\n",
      "model.layer3.0.bn2.num_batches_tracked: torch.Size([])\n",
      "model.layer3.0.downsample.0.weight: torch.Size([256, 128, 1, 1, 1])\n",
      "model.layer3.0.downsample.1.weight: torch.Size([256])\n",
      "model.layer3.0.downsample.1.bias: torch.Size([256])\n",
      "model.layer3.0.downsample.1.running_mean: torch.Size([256])\n",
      "model.layer3.0.downsample.1.running_var: torch.Size([256])\n",
      "model.layer3.0.downsample.1.num_batches_tracked: torch.Size([])\n",
      "model.layer4.0.conv1.weight: torch.Size([512, 256, 3, 3, 3])\n",
      "model.layer4.0.bn1.weight: torch.Size([512])\n",
      "model.layer4.0.bn1.bias: torch.Size([512])\n",
      "model.layer4.0.bn1.running_mean: torch.Size([512])\n",
      "model.layer4.0.bn1.running_var: torch.Size([512])\n",
      "model.layer4.0.bn1.num_batches_tracked: torch.Size([])\n",
      "model.layer4.0.conv2.weight: torch.Size([512, 512, 3, 3, 3])\n",
      "model.layer4.0.bn2.weight: torch.Size([512])\n",
      "model.layer4.0.bn2.bias: torch.Size([512])\n",
      "model.layer4.0.bn2.running_mean: torch.Size([512])\n",
      "model.layer4.0.bn2.running_var: torch.Size([512])\n",
      "model.layer4.0.bn2.num_batches_tracked: torch.Size([])\n",
      "model.layer4.0.downsample.0.weight: torch.Size([512, 256, 1, 1, 1])\n",
      "model.layer4.0.downsample.1.weight: torch.Size([512])\n",
      "model.layer4.0.downsample.1.bias: torch.Size([512])\n",
      "model.layer4.0.downsample.1.running_mean: torch.Size([512])\n",
      "model.layer4.0.downsample.1.running_var: torch.Size([512])\n",
      "model.layer4.0.downsample.1.num_batches_tracked: torch.Size([])\n",
      "model.fc.weight: torch.Size([10, 512])\n",
      "model.fc.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k, v in state_dict_2.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    else:\n",
    "        print(f\"{k}: {type(v)}\")  # Print type for non-tensor values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
