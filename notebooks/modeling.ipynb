{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Literal, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = [\n",
    "    \"ResNet\",\n",
    "    \"resnet10\",\n",
    "    \"resnet18\",\n",
    "    \"resnet34\",\n",
    "    \"resnet50\",\n",
    "    \"resnet101\",\n",
    "    \"resnet152\",\n",
    "    \"resnet200\",\n",
    "    \"get_resnet\",\n",
    "]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes: int, out_planes: int, stride: int = 1, dilation: int = 1) -> nn.Conv3d:\n",
    "    \"\"\"3x3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        dilation=dilation,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def downsample_basic_block(\n",
    "    x: torch.Tensor, planes: int, stride: int, no_cuda: bool = False\n",
    ") -> torch.Tensor:\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(\n",
    "        out.size(0), planes - out.size(1), out.size(2), out.size(3), out.size(4)\n",
    "    ).zero_()\n",
    "    if not no_cuda:\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        downsample: bool = None,\n",
    "    ):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        downsample: bool = None,\n",
    "    ):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "            padding=dilation,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Union[Bottleneck, BasicBlock],\n",
    "        layers: list[int],\n",
    "        num_classes: int = 10,\n",
    "        shortcut_type: Literal[\"A\", \"B\"] = \"B\",\n",
    "        no_cuda: bool = False,\n",
    "    ):\n",
    "        self.inplanes = 64\n",
    "        self.no_cuda = no_cuda\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            1, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], shortcut_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], shortcut_type, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], shortcut_type, stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], shortcut_type, stride=1, dilation=4)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        # fc_in_features = 2048 if block == Bottleneck else 512\n",
    "        self.fc = nn.Linear(self.inplanes, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal(m.weight, mode=\"fan_out\")\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Union[Bottleneck, BasicBlock],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        shortcut_type: Literal[\"A\", \"B\"],\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "    ):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == \"A\":\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride,\n",
    "                    no_cuda=self.no_cuda,\n",
    "                )\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    nn.BatchNorm3d(planes * block.expansion),\n",
    "                )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride=stride, dilation=dilation, downsample=downsample)\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [1, 1, 1, 1], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet200(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_resnet(model_depth: int = 18, **kwargs):\n",
    "    \"\"\"\n",
    "    Get a ResNet model based on the specified depth.\n",
    "\n",
    "    Args:\n",
    "        model_depth (int): Depth of the ResNet model (e.g., 10, 18, 34, 50, 101, 152, 200).\n",
    "        **kwargs: Additional arguments for the ResNet constructor.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The ResNet model.\n",
    "    \"\"\"\n",
    "    if model_depth == 10:\n",
    "        return resnet10(**kwargs)\n",
    "    elif model_depth == 18:\n",
    "        return resnet18(**kwargs)\n",
    "    elif model_depth == 34:\n",
    "        return resnet34(**kwargs)\n",
    "    elif model_depth == 50:\n",
    "        return resnet50(**kwargs)\n",
    "    elif model_depth == 101:\n",
    "        return resnet101(**kwargs)\n",
    "    elif model_depth == 152:\n",
    "        return resnet152(**kwargs)\n",
    "    elif model_depth == 200:\n",
    "        return resnet200(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported ResNet depth: {model_depth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from src.modeling.base_model import VertebraeClassifier\n",
    "\n",
    "\n",
    "class Med3DClassifier(VertebraeClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        model_depth: int = 18,\n",
    "        shortcut_type: Literal[\"A\", \"B\"] = \"B\",\n",
    "        load_pretrained: bool = True,\n",
    "        freeze_backbone: bool = True,\n",
    "        device: torch.device = torch.device(\"cuda\"),\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Classifier using Med3D ResNet backbone with optional pretrained weights.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            model_depth (int): Depth of ResNet (e.g., 10, 18, 34...).\n",
    "            shortcut_type (Literal['A', 'B']): Type of shortcut connection.\n",
    "            load_pretrained (bool): Whether to load pretrained weights from Med3D.\n",
    "            freeze_backbone (bool): Whether to freeze the backbone weights.\n",
    "        \"\"\"\n",
    "        super().__init__(num_classes)\n",
    "        self.device = device\n",
    "\n",
    "        self.model = get_resnet(\n",
    "            model_depth=model_depth,\n",
    "            num_classes=num_classes,\n",
    "            shortcut_type=shortcut_type,\n",
    "        )\n",
    "\n",
    "        if load_pretrained is not None:\n",
    "            self._load_med3d_weights(model_depth)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def _load_med3d_weights(self, model_depth: int) -> None:\n",
    "        \"\"\"\n",
    "        Load pretrained Med3D weights from HuggingFace, skipping the classification layer.\n",
    "        \"\"\"\n",
    "        hf_mapping = {\n",
    "            10: (\"TencentMedicalNet/MedicalNet-ResNet10\", \"resnet_10.pth\"),\n",
    "            18: (\"TencentMedicalNet/MedicalNet-ResNet18\", \"resnet_18.pth\"),\n",
    "            34: (\"TencentMedicalNet/MedicalNet-ResNet34\", \"resnet_34.pth\"),\n",
    "            50: (\"TencentMedicalNet/MedicalNet-ResNet50\", \"resnet_50.pth\"),\n",
    "            101: (\"TencentMedicalNet/MedicalNet-ResNet101\", \"resnet_101.pth\"),\n",
    "            152: (\"TencentMedicalNet/MedicalNet-ResNet152\", \"resnet_152.pth\"),\n",
    "            200: (\"TencentMedicalNet/MedicalNet-ResNet200\", \"resnet_200.pth\"),\n",
    "        }\n",
    "\n",
    "        if model_depth not in hf_mapping:\n",
    "            raise ValueError(f\"No pretrained weights available for model depth {model_depth}\")\n",
    "\n",
    "        repo_id, filename = hf_mapping[model_depth]\n",
    "        weight_path = hf_hub_download(repo_id=repo_id, filename=filename, cache_dir=\"../models/med3d\")\n",
    "\n",
    "        state_dict = torch.load(weight_path, map_location=self.device)[\"state_dict\"]\n",
    "        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items() if not k.startswith(\"conv-seg\")}            \n",
    "\n",
    "        missing, unexpected = self.model.load_state_dict(state_dict, strict=False)\n",
    "        print(\n",
    "            f\"[Med3D] Loaded weights with {len(missing)} missing and {len(unexpected)} unexpected keys. {len(state_dict)} total keys loaded.\" \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeecd7158ba04c67b0264b045ceafd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "resnet_34.pth:   0%|          | 0.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "med3D = Med3DClassifier(10, 34)\n",
    "med3D.to(\"cpu\")\n",
    "summary(med3D, input_size=(1, 64, 64, 64), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model \n",
    "model_path = \"med3d_resnet10.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_2 = torch.load(model_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convInit.conv.weight: torch.Size([32, 1, 3, 3, 3])\n",
      "down_layers.0.1.norm1.weight: torch.Size([32])\n",
      "down_layers.0.1.norm1.bias: torch.Size([32])\n",
      "down_layers.0.1.norm2.weight: torch.Size([32])\n",
      "down_layers.0.1.norm2.bias: torch.Size([32])\n",
      "down_layers.0.1.conv1.conv.weight: torch.Size([32, 32, 3, 3, 3])\n",
      "down_layers.0.1.conv2.conv.weight: torch.Size([32, 32, 3, 3, 3])\n",
      "down_layers.1.0.conv.weight: torch.Size([64, 32, 3, 3, 3])\n",
      "down_layers.1.1.norm1.weight: torch.Size([64])\n",
      "down_layers.1.1.norm1.bias: torch.Size([64])\n",
      "down_layers.1.1.norm2.weight: torch.Size([64])\n",
      "down_layers.1.1.norm2.bias: torch.Size([64])\n",
      "down_layers.1.1.conv1.conv.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "down_layers.1.1.conv2.conv.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "down_layers.1.2.norm1.weight: torch.Size([64])\n",
      "down_layers.1.2.norm1.bias: torch.Size([64])\n",
      "down_layers.1.2.norm2.weight: torch.Size([64])\n",
      "down_layers.1.2.norm2.bias: torch.Size([64])\n",
      "down_layers.1.2.conv1.conv.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "down_layers.1.2.conv2.conv.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "down_layers.2.0.conv.weight: torch.Size([128, 64, 3, 3, 3])\n",
      "down_layers.2.1.norm1.weight: torch.Size([128])\n",
      "down_layers.2.1.norm1.bias: torch.Size([128])\n",
      "down_layers.2.1.norm2.weight: torch.Size([128])\n",
      "down_layers.2.1.norm2.bias: torch.Size([128])\n",
      "down_layers.2.1.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "down_layers.2.1.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "down_layers.2.2.norm1.weight: torch.Size([128])\n",
      "down_layers.2.2.norm1.bias: torch.Size([128])\n",
      "down_layers.2.2.norm2.weight: torch.Size([128])\n",
      "down_layers.2.2.norm2.bias: torch.Size([128])\n",
      "down_layers.2.2.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "down_layers.2.2.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "down_layers.3.0.conv.weight: torch.Size([256, 128, 3, 3, 3])\n",
      "down_layers.3.1.norm1.weight: torch.Size([256])\n",
      "down_layers.3.1.norm1.bias: torch.Size([256])\n",
      "down_layers.3.1.norm2.weight: torch.Size([256])\n",
      "down_layers.3.1.norm2.bias: torch.Size([256])\n",
      "down_layers.3.1.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.1.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.2.norm1.weight: torch.Size([256])\n",
      "down_layers.3.2.norm1.bias: torch.Size([256])\n",
      "down_layers.3.2.norm2.weight: torch.Size([256])\n",
      "down_layers.3.2.norm2.bias: torch.Size([256])\n",
      "down_layers.3.2.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.2.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.3.norm1.weight: torch.Size([256])\n",
      "down_layers.3.3.norm1.bias: torch.Size([256])\n",
      "down_layers.3.3.norm2.weight: torch.Size([256])\n",
      "down_layers.3.3.norm2.bias: torch.Size([256])\n",
      "down_layers.3.3.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.3.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.4.norm1.weight: torch.Size([256])\n",
      "down_layers.3.4.norm1.bias: torch.Size([256])\n",
      "down_layers.3.4.norm2.weight: torch.Size([256])\n",
      "down_layers.3.4.norm2.bias: torch.Size([256])\n",
      "down_layers.3.4.conv1.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "down_layers.3.4.conv2.conv.weight: torch.Size([256, 256, 3, 3, 3])\n",
      "up_layers.0.0.norm1.weight: torch.Size([128])\n",
      "up_layers.0.0.norm1.bias: torch.Size([128])\n",
      "up_layers.0.0.norm2.weight: torch.Size([128])\n",
      "up_layers.0.0.norm2.bias: torch.Size([128])\n",
      "up_layers.0.0.conv1.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "up_layers.0.0.conv2.conv.weight: torch.Size([128, 128, 3, 3, 3])\n",
      "up_layers.1.0.norm1.weight: torch.Size([64])\n",
      "up_layers.1.0.norm1.bias: torch.Size([64])\n",
      "up_layers.1.0.norm2.weight: torch.Size([64])\n",
      "up_layers.1.0.norm2.bias: torch.Size([64])\n",
      "up_layers.1.0.conv1.conv.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "up_layers.1.0.conv2.conv.weight: torch.Size([64, 64, 3, 3, 3])\n",
      "up_layers.2.0.norm1.weight: torch.Size([32])\n",
      "up_layers.2.0.norm1.bias: torch.Size([32])\n",
      "up_layers.2.0.norm2.weight: torch.Size([32])\n",
      "up_layers.2.0.norm2.bias: torch.Size([32])\n",
      "up_layers.2.0.conv1.conv.weight: torch.Size([32, 32, 3, 3, 3])\n",
      "up_layers.2.0.conv2.conv.weight: torch.Size([32, 32, 3, 3, 3])\n",
      "up_samples.0.0.conv.weight: torch.Size([128, 256, 1, 1, 1])\n",
      "up_samples.1.0.conv.weight: torch.Size([64, 128, 1, 1, 1])\n",
      "up_samples.2.0.conv.weight: torch.Size([32, 64, 1, 1, 1])\n",
      "conv_final.0.weight: torch.Size([32])\n",
      "conv_final.0.bias: torch.Size([32])\n",
      "conv_final.2.conv.weight: torch.Size([105, 32, 1, 1, 1])\n",
      "conv_final.2.conv.bias: torch.Size([105])\n",
      "classifier.weight: torch.Size([10, 256])\n",
      "classifier.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k, v in state_dict_2.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    else:\n",
    "        print(f\"{k}: {type(v)}\")  # Print type for non-tensor values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegResNet(\n",
       "  (act_mod): ReLU(inplace=True)\n",
       "  (convInit): Convolution(\n",
       "    (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (down_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_samples): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode='trilinear')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_final): Sequential(\n",
       "    (0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Convolution(\n",
       "      (conv): Conv3d(32, 105, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout3d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from monai.bundle import ConfigParser\n",
    "\n",
    "model_dir = \"../models/monai_seg\"\n",
    "model_file = \"models/model.pt\"  # zakładamy, że w folderze models jest plik model.pt\n",
    "\n",
    "config_path = os.path.join(model_dir, \"configs\", \"inference.json\")\n",
    "parser = ConfigParser()\n",
    "parser.read_config(config_path)\n",
    "\n",
    "model = parser.get_parsed_content(\"network_def\")\n",
    "weights = torch.load(os.path.join(model_dir, model_file), map_location=\"cpu\")\n",
    "if isinstance(weights, dict) and \"state_dict\" in weights:\n",
    "    weights = weights[\"state_dict\"]\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model.pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "model.flatten = nn.Flatten()\n",
    "model.classifier = nn.Linear(256, 10)\n",
    "\n",
    "def forward(model, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = model.convInit(x)\n",
    "    for down in model.down_layers:\n",
    "        x = down(x)\n",
    "    x = model.pool(x)\n",
    "    x = model.flatten(x)\n",
    "    x = model.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 32, 64, 64, 64]             864\n",
      "         Dropout3d-2       [-1, 32, 64, 64, 64]               0\n",
      "          Identity-3       [-1, 32, 64, 64, 64]               0\n",
      "         GroupNorm-4       [-1, 32, 64, 64, 64]              64\n",
      "              ReLU-5       [-1, 32, 64, 64, 64]               0\n",
      "            Conv3d-6       [-1, 32, 64, 64, 64]          27,648\n",
      "         GroupNorm-7       [-1, 32, 64, 64, 64]              64\n",
      "              ReLU-8       [-1, 32, 64, 64, 64]               0\n",
      "            Conv3d-9       [-1, 32, 64, 64, 64]          27,648\n",
      "         ResBlock-10       [-1, 32, 64, 64, 64]               0\n",
      "           Conv3d-11       [-1, 64, 32, 32, 32]          55,296\n",
      "        GroupNorm-12       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-13       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-14       [-1, 64, 32, 32, 32]         110,592\n",
      "        GroupNorm-15       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-16       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-17       [-1, 64, 32, 32, 32]         110,592\n",
      "         ResBlock-18       [-1, 64, 32, 32, 32]               0\n",
      "        GroupNorm-19       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-20       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-21       [-1, 64, 32, 32, 32]         110,592\n",
      "        GroupNorm-22       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-23       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-24       [-1, 64, 32, 32, 32]         110,592\n",
      "         ResBlock-25       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-26      [-1, 128, 16, 16, 16]         221,184\n",
      "        GroupNorm-27      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-28      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-29      [-1, 128, 16, 16, 16]         442,368\n",
      "        GroupNorm-30      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-31      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-32      [-1, 128, 16, 16, 16]         442,368\n",
      "         ResBlock-33      [-1, 128, 16, 16, 16]               0\n",
      "        GroupNorm-34      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-35      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-36      [-1, 128, 16, 16, 16]         442,368\n",
      "        GroupNorm-37      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-38      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-39      [-1, 128, 16, 16, 16]         442,368\n",
      "         ResBlock-40      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-41         [-1, 256, 8, 8, 8]         884,736\n",
      "        GroupNorm-42         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-43         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-44         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-45         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-46         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-47         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-48         [-1, 256, 8, 8, 8]               0\n",
      "        GroupNorm-49         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-50         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-51         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-52         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-53         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-54         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-55         [-1, 256, 8, 8, 8]               0\n",
      "        GroupNorm-56         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-57         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-58         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-59         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-60         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-61         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-62         [-1, 256, 8, 8, 8]               0\n",
      "        GroupNorm-63         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-64         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-65         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-66         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-67         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-68         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-69         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-70         [-1, 128, 8, 8, 8]          32,768\n",
      "         Upsample-71      [-1, 128, 16, 16, 16]               0\n",
      "        GroupNorm-72      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-73      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-74      [-1, 128, 16, 16, 16]         442,368\n",
      "        GroupNorm-75      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-76      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-77      [-1, 128, 16, 16, 16]         442,368\n",
      "         ResBlock-78      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-79       [-1, 64, 16, 16, 16]           8,192\n",
      "         Upsample-80       [-1, 64, 32, 32, 32]               0\n",
      "        GroupNorm-81       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-82       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-83       [-1, 64, 32, 32, 32]         110,592\n",
      "        GroupNorm-84       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-85       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-86       [-1, 64, 32, 32, 32]         110,592\n",
      "         ResBlock-87       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-88       [-1, 32, 32, 32, 32]           2,048\n",
      "         Upsample-89       [-1, 32, 64, 64, 64]               0\n",
      "        GroupNorm-90       [-1, 32, 64, 64, 64]              64\n",
      "             ReLU-91       [-1, 32, 64, 64, 64]               0\n",
      "           Conv3d-92       [-1, 32, 64, 64, 64]          27,648\n",
      "        GroupNorm-93       [-1, 32, 64, 64, 64]              64\n",
      "             ReLU-94       [-1, 32, 64, 64, 64]               0\n",
      "           Conv3d-95       [-1, 32, 64, 64, 64]          27,648\n",
      "         ResBlock-96       [-1, 32, 64, 64, 64]               0\n",
      "        GroupNorm-97       [-1, 32, 64, 64, 64]              64\n",
      "             ReLU-98       [-1, 32, 64, 64, 64]               0\n",
      "             ReLU-99       [-1, 32, 64, 64, 64]               0\n",
      "          Conv3d-100      [-1, 105, 64, 64, 64]           3,465\n",
      "================================================================\n",
      "Total params: 18,799,401\n",
      "Trainable params: 18,799,401\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 2053.50\n",
      "Params size (MB): 71.71\n",
      "Estimated Total Size (MB): 2126.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model.to(\"cpu\")\n",
    "summary(model, input_size=(1, 64, 64, 64), device=\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.bundle import ConfigParser\n",
    "from torch import nn\n",
    "from src.modeling.base_model import VertebraeClassifier\n",
    "from src.config import SEG_MODEL_DIR\n",
    "\n",
    "\n",
    "class SegResNetClassifier(VertebraeClassifier):\n",
    "    def __init__(self, num_classes: int = 10) -> None:\n",
    "        \"\"\"\n",
    "        Classifier using MONAI's SegResNet backbone.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super().__init__(num_classes)\n",
    "        self._load_monai_model()\n",
    "        self._delete_decoder_layers()\n",
    "        self._add_classifier_layers()\n",
    "\n",
    "    def _load_monai_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Load the MONAI SegResNet model from the specified directory.\n",
    "        \"\"\"\n",
    "        config_path = SEG_MODEL_DIR / \"configs/inference.json\"\n",
    "        parser = ConfigParser()\n",
    "        parser.read_config(config_path)\n",
    "\n",
    "        self.model = parser.get_parsed_content(\"network_def\")\n",
    "        weights = torch.load(SEG_MODEL_DIR / \"models/model.pt\", map_location=\"cpu\")\n",
    "        if isinstance(weights, dict) and \"state_dict\" in weights:\n",
    "            weights = weights[\"state_dict\"]\n",
    "        self.model.load_state_dict(weights)\n",
    "\n",
    "\n",
    "    def _delete_decoder_layers(self) -> None:\n",
    "        \"\"\"\n",
    "        Remove decoder layers from the model to keep only the encoder part.\n",
    "        \"\"\"\n",
    "        for attr in [\"up_samples\", \"up_conv\", \"final_conv\"]:\n",
    "            if hasattr(self.model, attr):\n",
    "                delattr(self.model, attr)\n",
    "    \n",
    "    def _add_classifier_layers(self) -> None:\n",
    "        \"\"\"\n",
    "        Add classifier layers to the model.\n",
    "        \"\"\"\n",
    "        self.model.pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.model.flatten = nn.Flatten()\n",
    "        self.model.classifier = nn.Linear(256, self.num_classes)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        x = self.model.convInit(x)\n",
    "        for down in self.model.down_layers:\n",
    "            x = down(x)\n",
    "        x = self.model.pool(x)\n",
    "        x = self.model.flatten(x)\n",
    "        x = self.model.classifier(x)\n",
    "        return x            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 32, 64, 64, 64]             864\n",
      "          Identity-2       [-1, 32, 64, 64, 64]               0\n",
      "         GroupNorm-3       [-1, 32, 64, 64, 64]              64\n",
      "              ReLU-4       [-1, 32, 64, 64, 64]               0\n",
      "            Conv3d-5       [-1, 32, 64, 64, 64]          27,648\n",
      "         GroupNorm-6       [-1, 32, 64, 64, 64]              64\n",
      "              ReLU-7       [-1, 32, 64, 64, 64]               0\n",
      "            Conv3d-8       [-1, 32, 64, 64, 64]          27,648\n",
      "          ResBlock-9       [-1, 32, 64, 64, 64]               0\n",
      "           Conv3d-10       [-1, 64, 32, 32, 32]          55,296\n",
      "        GroupNorm-11       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-12       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-13       [-1, 64, 32, 32, 32]         110,592\n",
      "        GroupNorm-14       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-15       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-16       [-1, 64, 32, 32, 32]         110,592\n",
      "         ResBlock-17       [-1, 64, 32, 32, 32]               0\n",
      "        GroupNorm-18       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-19       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-20       [-1, 64, 32, 32, 32]         110,592\n",
      "        GroupNorm-21       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-22       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-23       [-1, 64, 32, 32, 32]         110,592\n",
      "         ResBlock-24       [-1, 64, 32, 32, 32]               0\n",
      "           Conv3d-25      [-1, 128, 16, 16, 16]         221,184\n",
      "        GroupNorm-26      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-27      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-28      [-1, 128, 16, 16, 16]         442,368\n",
      "        GroupNorm-29      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-30      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-31      [-1, 128, 16, 16, 16]         442,368\n",
      "         ResBlock-32      [-1, 128, 16, 16, 16]               0\n",
      "        GroupNorm-33      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-34      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-35      [-1, 128, 16, 16, 16]         442,368\n",
      "        GroupNorm-36      [-1, 128, 16, 16, 16]             256\n",
      "             ReLU-37      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-38      [-1, 128, 16, 16, 16]         442,368\n",
      "         ResBlock-39      [-1, 128, 16, 16, 16]               0\n",
      "           Conv3d-40         [-1, 256, 8, 8, 8]         884,736\n",
      "        GroupNorm-41         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-42         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-43         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-44         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-45         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-46         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-47         [-1, 256, 8, 8, 8]               0\n",
      "        GroupNorm-48         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-49         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-50         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-51         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-52         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-53         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-54         [-1, 256, 8, 8, 8]               0\n",
      "        GroupNorm-55         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-56         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-57         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-58         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-59         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-60         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-61         [-1, 256, 8, 8, 8]               0\n",
      "        GroupNorm-62         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-63         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-64         [-1, 256, 8, 8, 8]       1,769,472\n",
      "        GroupNorm-65         [-1, 256, 8, 8, 8]             512\n",
      "             ReLU-66         [-1, 256, 8, 8, 8]               0\n",
      "           Conv3d-67         [-1, 256, 8, 8, 8]       1,769,472\n",
      "         ResBlock-68         [-1, 256, 8, 8, 8]               0\n",
      "AdaptiveAvgPool3d-69         [-1, 256, 1, 1, 1]               0\n",
      "          Flatten-70                  [-1, 256]               0\n",
      "           Linear-71                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 17,593,322\n",
      "Trainable params: 17,593,322\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 905.00\n",
      "Params size (MB): 67.11\n",
      "Estimated Total Size (MB): 973.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model2 = SegResNetClassifier(num_classes=10)\n",
    "model2.to(\"cpu\")\n",
    "summary(model2, input_size=(1, 64, 64, 64), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Med3DClassifier(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Med3D] Loaded weights with 62 missing and 1 unexpected keys.\n",
      "Size 10: Trainable = 0.02 MB, Total = 54.78 MB\n",
      "[Med3D] Loaded weights with 102 missing and 1 unexpected keys.\n",
      "Size 18: Trainable = 0.02 MB, Total = 126.51 MB\n",
      "[Med3D] Loaded weights with 182 missing and 1 unexpected keys.\n",
      "Size 34: Trainable = 0.02 MB, Total = 242.14 MB\n",
      "[Med3D] Loaded weights with 267 missing and 1 unexpected keys.\n",
      "Size 50: Trainable = 0.08 MB, Total = 176.15 MB\n",
      "[Med3D] Loaded weights with 522 missing and 1 unexpected keys.\n",
      "Size 101: Trainable = 0.08 MB, Total = 325.10 MB\n",
      "[Med3D] Loaded weights with 777 missing and 1 unexpected keys.\n",
      "Size 152: Trainable = 0.08 MB, Total = 447.77 MB\n",
      "[Med3D] Loaded weights with 1017 missing and 1 unexpected keys.\n",
      "Size 200: Trainable = 0.08 MB, Total = 482.86 MB\n"
     ]
    }
   ],
   "source": [
    "from src.modeling.model_factory import create_model\n",
    "\n",
    "def params_to_mb(n_params: int) -> float:\n",
    "    return (n_params * 4) / (1024 ** 2)\n",
    "\n",
    "sizes = [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "for size in sizes:\n",
    "    med3d_frezed = create_model(\n",
    "        model_type='med3d',\n",
    "        num_classes=10,\n",
    "        model_depth=size,\n",
    "        device=\"cpu\",\n",
    "        freeze_backbone=True\n",
    "    )\n",
    "\n",
    "    trainable = sum(p.numel() for p in med3d_frezed.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in med3d_frezed.parameters())\n",
    "\n",
    "    print(f\"Size {size}: Trainable = {params_to_mb(trainable):.2f} MB, Total = {params_to_mb(total):.2f} MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
